{"nbformat":4,"nbformat_minor":2,"metadata":{"accelerator":"GPU","colab":{"name":"CIFAR-10 experiments.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"interpreter":{"hash":"e1e652ea0f718c1c1a715d4298748f07ddc07cd094f3f128b826b9a1f676b1d0"},"kernelspec":{"display_name":"Python 3.8.10 64-bit ('default': conda)","name":"python3"},"language_info":{"name":"python","version":"3.8.10"}},"cells":[{"cell_type":"markdown","source":["# Imports and setting up libraries"],"metadata":{"id":"YpqOGBurVoHF"}},{"cell_type":"code","execution_count":null,"source":["%load_ext autoreload\n","%autoreload 2"],"outputs":[],"metadata":{"id":"tp1a2KSRWsNk"}},{"cell_type":"code","execution_count":null,"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"outputs":[],"metadata":{"id":"ZLAgTR8nPzk-"}},{"cell_type":"code","execution_count":null,"source":["# importing necessary libraries\n","import os\n","from tqdm.auto import tqdm\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import torch\n","import torch.optim as optim\n","import torch.nn as nn\n","from torch.utils.data.sampler import SubsetRandomSampler\n","import torchvision\n","from torchvision import transforms as T"],"outputs":[],"metadata":{"id":"Nm9fxgGKWgSg"}},{"cell_type":"code","execution_count":null,"source":["!pip install torchinfo\n","from torchinfo import summary"],"outputs":[],"metadata":{"id":"0kQ-cHcNw6Vo"}},{"cell_type":"code","execution_count":null,"source":["os.chdir('/content/gdrive/MyDrive/Deep Learning/cifar10-experiments/')"],"outputs":[],"metadata":{"id":"J0JTOII6V32O"}},{"cell_type":"code","execution_count":null,"source":["# using GPU if available\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","device"],"outputs":[],"metadata":{"id":"MMYrwy8owkIY"}},{"cell_type":"code","execution_count":null,"source":["# ensuring reproducibility of code\n","random_seed = 42\n","torch.manual_seed(random_seed)\n","np.random.seed(random_seed)\n","torch.manual_seed(random_seed)\n","torch.cuda.manual_seed(random_seed)\n","torch.cuda.manual_seed_all(random_seed)\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False"],"outputs":[],"metadata":{"id":"KgiKywjJ1jFK"}},{"cell_type":"markdown","source":["# Loading data"],"metadata":{"id":"7xjajNt-VxG-"}},{"cell_type":"code","execution_count":null,"source":["# defining transforms and data augmentation\n","train_transform = T.Compose(\n","    [T.RandomHorizontalFlip(),\n","     T.RandomCrop(32, padding = 4),\n","     T.ToTensor(),\n","     T.Normalize((0.4914, 0.4822, 0.4465),\n","                             (0.2023, 0.1994, 0.2010))])\n","\n","valid_transform = T.Compose(\n","    [T.ToTensor(),\n","     T.Normalize((0.4914, 0.4822, 0.4465),\n","                             (0.2023, 0.1994, 0.2010))])\n","\n","test_transform = T.Compose(\n","    [T.ToTensor(),\n","     T.Normalize((0.4914, 0.4822, 0.4465),\n","                             (0.2023, 0.1994, 0.2010))])"],"outputs":[],"metadata":{"id":"pgp1rHOwf73u"}},{"cell_type":"code","execution_count":null,"source":["# loading data\n","trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n","                                        download=True, transform=train_transform)\n","\n","validset = torchvision.datasets.CIFAR10(root='./data', train=True,\n","                                        download=True, transform=valid_transform)\n","\n","testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n","                                       download=True, transform=test_transform)"],"outputs":[],"metadata":{"id":"nh4YGqpeUlia"}},{"cell_type":"code","execution_count":null,"source":["# some parameters for the data\n","batch_size = 128\n","val_size = 0.10"],"outputs":[],"metadata":{"id":"_GM6EiWxMfyN"}},{"cell_type":"code","execution_count":null,"source":["# validation split\n","num_train = len(trainset)\n","indices = list(range(num_train))\n","split = int(np.floor(val_size * num_train))\n","np.random.shuffle(indices)\n","\n","train_idx, valid_idx = indices[split:], indices[:split]\n","train_sampler = SubsetRandomSampler(train_idx)\n","valid_sampler = SubsetRandomSampler(valid_idx)"],"outputs":[],"metadata":{"id":"rR5EsTOZUnDh"}},{"cell_type":"code","execution_count":null,"source":["# defining dataloaders\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size = batch_size,\n","                                          sampler = train_sampler, num_workers = 2)\n","validloader = torch.utils.data.DataLoader(validset, batch_size = batch_size,\n","                                          sampler = valid_sampler, num_workers = 2)\n","testloader = torch.utils.data.DataLoader(testset, batch_size = batch_size,\n","                                         shuffle = False, num_workers = 2)"],"outputs":[],"metadata":{"id":"4dBhLImqUo93"}},{"cell_type":"code","execution_count":null,"source":["# class names in CIFAR-10\n","classes = ('plane', 'car', 'bird', 'cat',\n","           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"],"outputs":[],"metadata":{"id":"EjrPlIdGOiJI"}},{"cell_type":"code","execution_count":null,"source":["# functions to show an image\n","def imshow(img):\n","    img = img / 2 + 0.5     # unnormalize\n","    npimg = img.numpy()\n","    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n","    plt.show()\n","\n","# get some random training images\n","dataiter = iter(trainloader)\n","images, labels = dataiter.next()\n","\n","# show images\n","imshow(torchvision.utils.make_grid(images[:8]))\n","# print labels\n","print(' '.join('%5s' % classes[labels[j]] for j in range(8)))"],"outputs":[],"metadata":{"id":"DaUbxzUdNa3h"}},{"cell_type":"markdown","source":["# Network definitions"],"metadata":{"id":"aXizPPx_3duz"}},{"cell_type":"code","execution_count":null,"source":["arch = \"densenetlike\""],"outputs":[],"metadata":{"id":"8adhKFsgWDq3"}},{"cell_type":"code","execution_count":null,"source":["# importing model to be used\n","model_file = __import__(f'models.{arch}', fromlist=[arch])\n","base_arch = getattr(model_file, arch)"],"outputs":[],"metadata":{"id":"X2vbYK6FVDnk"}},{"cell_type":"code","execution_count":null,"source":["# moving net to GPU and summary of model architecture\n","net = base_arch()\n","net.to(device)\n","summary(net, input_size = (batch_size, 3, 32, 32))"],"outputs":[],"metadata":{"id":"I5ih5G0cfef0"}},{"cell_type":"code","execution_count":null,"source":["# defining loss, optimizer and lr scheduler\n","learning_rate = 3e-3\n","decay = 0.10\n","opt_milestones = [50, 75]\n","gamma = 0.10\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.AdamW(net.parameters(), lr = learning_rate, weight_decay = decay)\n","scheduler = optim.lr_scheduler.MultiStepLR(optimizer, opt_milestones, gamma = gamma)"],"outputs":[],"metadata":{"id":"0qBAsYbReUiU"}},{"cell_type":"markdown","source":["# Training"],"metadata":{"id":"i2LUEyEb3gGm"}},{"cell_type":"code","execution_count":null,"source":["keys = ['epochs', 'loss', 'acc', 'val_loss', 'val_acc']\n","history = {key: [] for key in keys}"],"outputs":[],"metadata":{"id":"5kWtiQH6Pefo"}},{"cell_type":"code","execution_count":null,"source":["def train(epoch):\n","    \"\"\"training loop for one epoch\"\"\"\n","    net.train()\n","\n","    train_loss = 0.0\n","    train_total = 0\n","    train_correct = 0\n","\n","    for data in tqdm(trainloader):\n","        # get the inputs; data is a list of [inputs, labels]\n","        inputs, labels = data\n","        inputs, labels = inputs.to(device), labels.to(device)\n","\n","        # zero the parameter gradients\n","        optimizer.zero_grad()\n","\n","        # forward + backward + optimize\n","        outputs = net(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        # keep track of loss and accuracy\n","        train_loss += loss.item()\n","        predicted = torch.argmax(outputs.data, dim = 1)\n","        train_total += labels.size(0)\n","        train_correct += (predicted == labels).sum().item()\n","\n","    train_accuracy = 100 * (train_correct / train_total)\n","    history['epochs'].append(epoch + 1)\n","    history['loss'].append(train_loss)\n","    history['acc'].append(train_accuracy)\n","\n","    # print statistics\n","    print(f'    Loss of the network on the {train_total} training images: {train_loss}')\n","    print(f'    Accuracy of the network on the {train_total} training images: {train_accuracy}%')"],"outputs":[],"metadata":{"id":"QoWsxIBuXAlH"}},{"cell_type":"code","execution_count":null,"source":["def validation():\n","    \"\"\"validation set evaluation for one epoch\"\"\"\n","    valid_correct = 0\n","    valid_total = 0\n","    valid_loss = 0\n","\n","    # since we're not training, we don't need to calculate the gradients\n","    with torch.no_grad():\n","        net.eval()\n","        for data in validloader:\n","            images, labels = data\n","            images, labels = images.to(device), labels.to(device)\n","            # calculate outputs by running images through the network\n","            outputs = net(images)\n","            valid_loss += criterion(outputs, labels)\n","            # the class with the highest energy is what we choose as prediction\n","            predicted = torch.argmax(outputs.data, dim = 1)\n","            valid_total += labels.size(0)\n","            valid_correct += (predicted == labels).sum().item()\n","    \n","    valid_accuracy = 100 * (valid_correct / valid_total)\n","    history['val_loss'].append(valid_loss)\n","    history['val_acc'].append(valid_accuracy)\n","    \n","    print(f'    Accuracy of the network on the {valid_total} validation images: {valid_accuracy}%')"],"outputs":[],"metadata":{"id":"Lj7j8o8yXEIo"}},{"cell_type":"code","execution_count":null,"source":["# training\n","epochs = 100\n","\n","for epoch in range(epochs):  # loop over the dataset multiple time\n","    print(\"Epoch\", epoch + 1)\n","    train(epoch)\n","    validation()\n","    print()\n","    scheduler.step()\n","\n","print('Finished Training')"],"outputs":[],"metadata":{"id":"em9M92s3XIlh"}},{"cell_type":"code","execution_count":null,"source":["plt.figure(figsize= (12,4))\n","plt.subplot(1,2,1)\n","plt.plot(history['epochs'], history['loss'], label='loss') \n","plt.plot(history['epochs'], history['val_loss'], label='Val loss')\n","plt.xlabel('Epochs')\n","plt.title(\"Loss Visualisation\")\n","plt.legend()\n","\n","plt.subplot(1,2,2)\n","plt.plot(history['epochs'], history['acc'], label='accuracy')  \n","plt.plot(history['epochs'], history['val_acc'], label='Val accuracy')\n","plt.xlabel('Epochs')\n","plt.title(\"Accuracy Visualisation\")\n","plt.legend()"],"outputs":[],"metadata":{"id":"1lkw1IV8PxSM"}},{"cell_type":"code","execution_count":null,"source":["# saving model\n","model_save_name = f'cifar10{arch}.pt'\n","path = f\"/content/gdrive/My Drive/Deep Learning/cifar10-experiments/trained models/{model_save_name}\" \n","torch.save(net, path)"],"outputs":[],"metadata":{"id":"9y1FESd5IDyh"}},{"cell_type":"markdown","source":["# Testing"],"metadata":{"id":"_fiQ93Lt3jgX"}},{"cell_type":"code","execution_count":null,"source":["# loading model\n","model_save_name = f'cifar10{arch}.pt'\n","PATH = f\"/content/gdrive/My Drive/Deep Learning/cifar10-experiments/trained models/{model_save_name}\"\n","model = torch.load(PATH, map_location=torch.device(device))"],"outputs":[],"metadata":{"id":"RjNE2vpSJAm5"}},{"cell_type":"code","execution_count":null,"source":["# moving model to GPU\n","model.to(device);"],"outputs":[],"metadata":{"id":"s7YuwXdpXRqE"}},{"cell_type":"code","execution_count":null,"source":["# evaluating on test set\n","correct = 0\n","total = 0\n","# since we're not training, we don't need to calculate the gradients for our outputs\n","with torch.no_grad():\n","    model.eval()\n","    for data in testloader:\n","        images, labels = data\n","        images, labels = images.to(device), labels.to(device)\n","        # calculate outputs by running images through the network\n","        outputs = model(images)\n","        # the class with the highest energy is what we choose as prediction\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","print(f'Accuracy of the network on the {total} test images: {100 * correct / total}')"],"outputs":[],"metadata":{"id":"Wts_BReX4nZ4"}},{"cell_type":"code","execution_count":null,"source":["# counting predictions for each class\n","correct_pred = {classname: 0 for classname in classes}\n","total_pred = {classname: 0 for classname in classes}\n","\n","# again no gradients needed\n","with torch.no_grad():\n","    model.eval()\n","    for data in testloader:\n","        images, labels = data\n","        images, labels = images.to(device), labels.to(device)\n","        outputs = model(images)\n","        _, predictions = torch.max(outputs, 1)\n","        # collect the correct predictions for each class\n","        for label, prediction in zip(labels, predictions):\n","            if label == prediction:\n","                correct_pred[classes[label]] += 1\n","            total_pred[classes[label]] += 1\n","\n","# print accuracy for each class\n","for classname, correct_count in correct_pred.items():\n","    accuracy = 100 * float(correct_count) / total_pred[classname]\n","    print(f\"Accuracy for class {classname} is: {accuracy}\")"],"outputs":[],"metadata":{"id":"a8oeVtg2Nqo_"}}]}