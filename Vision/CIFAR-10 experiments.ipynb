{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CIFAR-10 experiments.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"YpqOGBurVoHF"},"source":["# Imports and setting up libraries"]},{"cell_type":"code","metadata":{"id":"tp1a2KSRWsNk","executionInfo":{"status":"ok","timestamp":1626836911496,"user_tz":-330,"elapsed":612,"user":{"displayName":"Abhirath Anand","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgK3G6ETxbNbUGxfG49-G1F7hu8ECK1VefIB-8NKA=s64","userId":"10495731995593710191"}}},"source":["%load_ext autoreload\n","%autoreload 2"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZLAgTR8nPzk-","executionInfo":{"status":"ok","timestamp":1626836912094,"user_tz":-330,"elapsed":9,"user":{"displayName":"Abhirath Anand","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgK3G6ETxbNbUGxfG49-G1F7hu8ECK1VefIB-8NKA=s64","userId":"10495731995593710191"}},"outputId":"fffb5f5e-8c09-4273-9f70-3779d189d3c9"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Nm9fxgGKWgSg","executionInfo":{"status":"ok","timestamp":1626836912432,"user_tz":-330,"elapsed":342,"user":{"displayName":"Abhirath Anand","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgK3G6ETxbNbUGxfG49-G1F7hu8ECK1VefIB-8NKA=s64","userId":"10495731995593710191"}}},"source":["# importing necessary libraries\n","import numpy as np\n","import os\n","import matplotlib.pyplot as plt\n","import torch\n","import torch.optim as optim\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data.sampler import SubsetRandomSampler\n","import torchvision\n","from torchvision import transforms"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P9u4Qyu_VmC9","executionInfo":{"status":"ok","timestamp":1626836915320,"user_tz":-330,"elapsed":2889,"user":{"displayName":"Abhirath Anand","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgK3G6ETxbNbUGxfG49-G1F7hu8ECK1VefIB-8NKA=s64","userId":"10495731995593710191"}},"outputId":"c2428009-a2ea-45b7-9c2e-ce038fc6a474"},"source":["!pip install torchinfo\n","from torchinfo import summary"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: torchinfo in /usr/local/lib/python3.7/dist-packages (1.5.2)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"J0JTOII6V32O","executionInfo":{"status":"ok","timestamp":1626836915320,"user_tz":-330,"elapsed":12,"user":{"displayName":"Abhirath Anand","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgK3G6ETxbNbUGxfG49-G1F7hu8ECK1VefIB-8NKA=s64","userId":"10495731995593710191"}}},"source":["os.chdir('/content/gdrive/MyDrive/Deep Learning/pytorch-experiments/Vision/')"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MMYrwy8owkIY","executionInfo":{"status":"ok","timestamp":1626836915320,"user_tz":-330,"elapsed":11,"user":{"displayName":"Abhirath Anand","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgK3G6ETxbNbUGxfG49-G1F7hu8ECK1VefIB-8NKA=s64","userId":"10495731995593710191"}},"outputId":"d76a650f-fadf-42b3-b9dd-ac9cfd1dde4f"},"source":["# using GPU if available\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","device"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"KgiKywjJ1jFK","executionInfo":{"status":"ok","timestamp":1626836915320,"user_tz":-330,"elapsed":10,"user":{"displayName":"Abhirath Anand","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgK3G6ETxbNbUGxfG49-G1F7hu8ECK1VefIB-8NKA=s64","userId":"10495731995593710191"}}},"source":["# ensuring reproducibility of code\n","random_seed = 42\n","torch.manual_seed(random_seed)\n","np.random.seed(random_seed)\n","torch.manual_seed(random_seed)\n","torch.cuda.manual_seed(random_seed)\n","torch.cuda.manual_seed_all(random_seed)\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7xjajNt-VxG-"},"source":["# Loading data"]},{"cell_type":"code","metadata":{"id":"W8xLfs33Xyxe","executionInfo":{"status":"ok","timestamp":1626836915321,"user_tz":-330,"elapsed":11,"user":{"displayName":"Abhirath Anand","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgK3G6ETxbNbUGxfG49-G1F7hu8ECK1VefIB-8NKA=s64","userId":"10495731995593710191"}}},"source":["# some hyperparameters for the network\n","batch_size = 128\n","val_size = 0.1\n","epochs = 100\n","learning_rate = 3e-3\n","decay = 0.1\n","opt_milestones = [50, 75]"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"pgp1rHOwf73u","executionInfo":{"status":"ok","timestamp":1626836915321,"user_tz":-330,"elapsed":10,"user":{"displayName":"Abhirath Anand","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgK3G6ETxbNbUGxfG49-G1F7hu8ECK1VefIB-8NKA=s64","userId":"10495731995593710191"}}},"source":["# defining transforms and data augmentation\n","train_transform = transforms.Compose(\n","    [transforms.RandomCrop(32, padding = 4),\n","    transforms.RandomHorizontalFlip(),\n","     transforms.ToTensor(),\n","     transforms.Normalize((0.4914, 0.4822, 0.4465),\n","                             (0.2023, 0.1994, 0.2010))])\n","\n","valid_transform = transforms.Compose(\n","    [transforms.ToTensor(),\n","     transforms.Normalize((0.4914, 0.4822, 0.4465),\n","                             (0.2023, 0.1994, 0.2010))])\n","\n","test_transform = transforms.Compose(\n","    [transforms.ToTensor(),\n","     transforms.Normalize((0.4914, 0.4822, 0.4465),\n","                             (0.2023, 0.1994, 0.2010))])"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nh4YGqpeUlia","executionInfo":{"status":"ok","timestamp":1626836919352,"user_tz":-330,"elapsed":4041,"user":{"displayName":"Abhirath Anand","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgK3G6ETxbNbUGxfG49-G1F7hu8ECK1VefIB-8NKA=s64","userId":"10495731995593710191"}},"outputId":"c3b690a1-d465-4955-91c3-0f0aaf489247"},"source":["# loading data\n","trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n","                                        download=True, transform=train_transform)\n","\n","validset = torchvision.datasets.CIFAR10(root='./data', train=True,\n","                                        download=True, transform=valid_transform)\n","\n","testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n","                                       download=True, transform=test_transform)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Files already downloaded and verified\n","Files already downloaded and verified\n","Files already downloaded and verified\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rR5EsTOZUnDh","executionInfo":{"status":"ok","timestamp":1626836919354,"user_tz":-330,"elapsed":22,"user":{"displayName":"Abhirath Anand","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgK3G6ETxbNbUGxfG49-G1F7hu8ECK1VefIB-8NKA=s64","userId":"10495731995593710191"}}},"source":["# validation split\n","num_train = len(trainset)\n","indices = list(range(num_train))\n","split = int(np.floor(val_size * num_train))\n","np.random.shuffle(indices)\n","\n","train_idx, valid_idx = indices[split:], indices[:split]\n","train_sampler = SubsetRandomSampler(train_idx)\n","valid_sampler = SubsetRandomSampler(valid_idx)"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"4dBhLImqUo93","executionInfo":{"status":"ok","timestamp":1626836919354,"user_tz":-330,"elapsed":20,"user":{"displayName":"Abhirath Anand","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgK3G6ETxbNbUGxfG49-G1F7hu8ECK1VefIB-8NKA=s64","userId":"10495731995593710191"}}},"source":["# defining dataloaders\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n","                                          sampler = train_sampler, num_workers=2)\n","validloader = torch.utils.data.DataLoader(validset, batch_size=batch_size,\n","                                          sampler = valid_sampler, num_workers=2)\n","testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n","                                         shuffle=False, num_workers=2)"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"X2vbYK6FVDnk","executionInfo":{"status":"ok","timestamp":1626836919355,"user_tz":-330,"elapsed":20,"user":{"displayName":"Abhirath Anand","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgK3G6ETxbNbUGxfG49-G1F7hu8ECK1VefIB-8NKA=s64","userId":"10495731995593710191"}}},"source":["# importing model to be used\n","from models.vgglike import VGGlike"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"I5ih5G0cfef0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626836923071,"user_tz":-330,"elapsed":3735,"user":{"displayName":"Abhirath Anand","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgK3G6ETxbNbUGxfG49-G1F7hu8ECK1VefIB-8NKA=s64","userId":"10495731995593710191"}},"outputId":"57e7c266-f96a-4ec1-93de-34f037b7ff30"},"source":["# moving net to GPU and summary of model architecture\n","net = VGGlike(nclasses = 10)\n","net.to(device)\n","summary(net, input_size = (batch_size, 3, 32, 32))"],"execution_count":14,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n","  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["==========================================================================================\n","Layer (type:depth-idx)                   Output Shape              Param #\n","==========================================================================================\n","VGGlike                                  --                        --\n","├─Conv2d: 1-1                            [128, 32, 32, 32]         896\n","├─BatchNorm2d: 1-2                       [128, 32, 32, 32]         64\n","├─Conv2d: 1-3                            [128, 64, 32, 32]         18,496\n","├─Dropout: 1-4                           [128, 64, 32, 32]         --\n","├─MaxPool2d: 1-5                         [128, 64, 16, 16]         --\n","├─Conv2d: 1-6                            [128, 128, 16, 16]        73,856\n","├─BatchNorm2d: 1-7                       [128, 128, 16, 16]        256\n","├─Conv2d: 1-8                            [128, 128, 16, 16]        147,584\n","├─Dropout: 1-9                           [128, 128, 16, 16]        --\n","├─MaxPool2d: 1-10                        [128, 128, 8, 8]          --\n","├─Conv2d: 1-11                           [128, 256, 8, 8]          295,168\n","├─BatchNorm2d: 1-12                      [128, 256, 8, 8]          512\n","├─Conv2d: 1-13                           [128, 256, 8, 8]          590,080\n","├─Dropout: 1-14                          [128, 256, 8, 8]          --\n","├─MaxPool2d: 1-15                        [128, 256, 4, 4]          --\n","├─Linear: 1-16                           [128, 256]                1,048,832\n","├─Dropout: 1-17                          [128, 256]                --\n","├─Linear: 1-18                           [128, 10]                 2,570\n","==========================================================================================\n","Total params: 2,178,314\n","Trainable params: 2,178,314\n","Non-trainable params: 0\n","Total mult-adds (G): 17.18\n","==========================================================================================\n","Input size (MB): 1.57\n","Forward/backward pass size (MB): 285.49\n","Params size (MB): 8.71\n","Estimated Total Size (MB): 295.77\n","=========================================================================================="]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"0qBAsYbReUiU","executionInfo":{"status":"ok","timestamp":1626836923071,"user_tz":-330,"elapsed":6,"user":{"displayName":"Abhirath Anand","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgK3G6ETxbNbUGxfG49-G1F7hu8ECK1VefIB-8NKA=s64","userId":"10495731995593710191"}}},"source":["# defining loss, optimizer and lr scheduler\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.AdamW(net.parameters(), lr = learning_rate, weight_decay = decay)\n","scheduler = optim.lr_scheduler.MultiStepLR(optimizer, opt_milestones)"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"QoWsxIBuXAlH","executionInfo":{"status":"ok","timestamp":1626836923072,"user_tz":-330,"elapsed":5,"user":{"displayName":"Abhirath Anand","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgK3G6ETxbNbUGxfG49-G1F7hu8ECK1VefIB-8NKA=s64","userId":"10495731995593710191"}}},"source":["def train(epoch):\n","    \"\"\"training loop for one epoch\"\"\"\n","    net.train()\n","\n","    running_loss = 0.0\n","    train_total = 0\n","    train_correct = 0\n","\n","    for i, data in enumerate(trainloader, 0):\n","        # get the inputs; data is a list of [inputs, labels]\n","        inputs, labels = data\n","        inputs, labels = inputs.to(device), labels.to(device)\n","\n","        # zero the parameter gradients\n","        optimizer.zero_grad()\n","\n","        # forward + backward + optimize\n","        outputs = net(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        # keep track of loss and accuracy\n","        running_loss += loss.item()\n","        predicted = torch.argmax(outputs.data, dim = 1)\n","        train_total += labels.size(0)\n","        train_correct += (predicted == labels).sum().item()\n","    \n","    scheduler.step() # only after every epoch\n","\n","    # print statistics\n","    train_accuracy = 100 * (train_correct / train_total)\n","    print(\"Epoch\", epoch + 1)\n","    print(f'    Loss of the network on the {train_total} training images: {running_loss}')\n","    print(f'    Accuracy of the network on the {train_total} training images: {train_accuracy}%')"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"Lj7j8o8yXEIo","executionInfo":{"status":"ok","timestamp":1626836923072,"user_tz":-330,"elapsed":5,"user":{"displayName":"Abhirath Anand","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgK3G6ETxbNbUGxfG49-G1F7hu8ECK1VefIB-8NKA=s64","userId":"10495731995593710191"}}},"source":["def validation():\n","    \"\"\"validation set evaluation for one epoch\"\"\"\n","    valid_correct = 0\n","    valid_total = 0\n","\n","    # since we're not training, we don't need to calculate the gradients\n","    with torch.no_grad():\n","        net.eval()\n","\n","        for data in validloader:\n","            images, labels = data\n","            images, labels = images.to(device), labels.to(device)\n","            # calculate outputs by running images through the network\n","            outputs = net(images)\n","            # the class with the highest energy is what we choose as prediction\n","            predicted = torch.argmax(outputs.data, dim = 1)\n","            valid_total += labels.size(0)\n","            valid_correct += (predicted == labels).sum().item()\n","\n","    valid_accuracy = 100 * (valid_correct / valid_total)\n","    print(f'    Accuracy of the network on the {valid_total} validation images: {valid_accuracy}%')"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"em9M92s3XIlh","executionInfo":{"status":"ok","timestamp":1626838632371,"user_tz":-330,"elapsed":1709304,"user":{"displayName":"Abhirath Anand","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgK3G6ETxbNbUGxfG49-G1F7hu8ECK1VefIB-8NKA=s64","userId":"10495731995593710191"}},"outputId":"3047e803-0ba2-4e6d-f057-ca8de3548675"},"source":["# training\n","\n","for epoch in range(epochs):  # loop over the dataset multiple times\n","    train(epoch)\n","    validation()\n","\n","print('Finished Training')"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Epoch 1\n","    Loss of the network on the 45000 training images: 694.502295255661\n","    Accuracy of the network on the 45000 training images: 25.964444444444446%\n","    Accuracy of the network on the 5000 validation images: 33.22%\n","Epoch 2\n","    Loss of the network on the 45000 training images: 571.9361778497696\n","    Accuracy of the network on the 45000 training images: 38.99333333333333%\n","    Accuracy of the network on the 5000 validation images: 45.34%\n","Epoch 3\n","    Loss of the network on the 45000 training images: 492.758381485939\n","    Accuracy of the network on the 45000 training images: 48.44%\n","    Accuracy of the network on the 5000 validation images: 53.779999999999994%\n","Epoch 4\n","    Loss of the network on the 45000 training images: 433.5153072476387\n","    Accuracy of the network on the 45000 training images: 54.80222222222222%\n","    Accuracy of the network on the 5000 validation images: 56.02%\n","Epoch 5\n","    Loss of the network on the 45000 training images: 392.5318638086319\n","    Accuracy of the network on the 45000 training images: 59.611111111111114%\n","    Accuracy of the network on the 5000 validation images: 61.760000000000005%\n","Epoch 6\n","    Loss of the network on the 45000 training images: 358.8526608943939\n","    Accuracy of the network on the 45000 training images: 63.24444444444445%\n","    Accuracy of the network on the 5000 validation images: 64.34%\n","Epoch 7\n","    Loss of the network on the 45000 training images: 336.23405116796494\n","    Accuracy of the network on the 45000 training images: 65.5111111111111%\n","    Accuracy of the network on the 5000 validation images: 63.4%\n","Epoch 8\n","    Loss of the network on the 45000 training images: 319.85054939985275\n","    Accuracy of the network on the 45000 training images: 67.88666666666666%\n","    Accuracy of the network on the 5000 validation images: 59.36%\n","Epoch 9\n","    Loss of the network on the 45000 training images: 304.77510875463486\n","    Accuracy of the network on the 45000 training images: 69.39111111111112%\n","    Accuracy of the network on the 5000 validation images: 65.62%\n","Epoch 10\n","    Loss of the network on the 45000 training images: 293.9242929816246\n","    Accuracy of the network on the 45000 training images: 70.40444444444445%\n","    Accuracy of the network on the 5000 validation images: 71.8%\n","Epoch 11\n","    Loss of the network on the 45000 training images: 284.95038998126984\n","    Accuracy of the network on the 45000 training images: 71.50222222222223%\n","    Accuracy of the network on the 5000 validation images: 67.72%\n","Epoch 12\n","    Loss of the network on the 45000 training images: 277.5379686951637\n","    Accuracy of the network on the 45000 training images: 72.28222222222223%\n","    Accuracy of the network on the 5000 validation images: 65.44%\n","Epoch 13\n","    Loss of the network on the 45000 training images: 270.3477293252945\n","    Accuracy of the network on the 45000 training images: 73.11777777777777%\n","    Accuracy of the network on the 5000 validation images: 72.86%\n","Epoch 14\n","    Loss of the network on the 45000 training images: 261.41211691498756\n","    Accuracy of the network on the 45000 training images: 73.91555555555556%\n","    Accuracy of the network on the 5000 validation images: 66.92%\n","Epoch 15\n","    Loss of the network on the 45000 training images: 257.0389603674412\n","    Accuracy of the network on the 45000 training images: 74.3711111111111%\n","    Accuracy of the network on the 5000 validation images: 72.14%\n","Epoch 16\n","    Loss of the network on the 45000 training images: 257.5409027338028\n","    Accuracy of the network on the 45000 training images: 74.13777777777779%\n","    Accuracy of the network on the 5000 validation images: 68.54%\n","Epoch 17\n","    Loss of the network on the 45000 training images: 251.6983439028263\n","    Accuracy of the network on the 45000 training images: 75.13333333333333%\n","    Accuracy of the network on the 5000 validation images: 72.28%\n","Epoch 18\n","    Loss of the network on the 45000 training images: 249.58078169822693\n","    Accuracy of the network on the 45000 training images: 75.20444444444443%\n","    Accuracy of the network on the 5000 validation images: 71.8%\n","Epoch 19\n","    Loss of the network on the 45000 training images: 244.81056016683578\n","    Accuracy of the network on the 45000 training images: 75.74888888888889%\n","    Accuracy of the network on the 5000 validation images: 70.94%\n","Epoch 20\n","    Loss of the network on the 45000 training images: 238.4517433643341\n","    Accuracy of the network on the 45000 training images: 76.20444444444445%\n","    Accuracy of the network on the 5000 validation images: 71.88%\n","Epoch 21\n","    Loss of the network on the 45000 training images: 237.30777645111084\n","    Accuracy of the network on the 45000 training images: 76.48222222222222%\n","    Accuracy of the network on the 5000 validation images: 71.58%\n","Epoch 22\n","    Loss of the network on the 45000 training images: 234.92718574404716\n","    Accuracy of the network on the 45000 training images: 76.82222222222222%\n","    Accuracy of the network on the 5000 validation images: 73.6%\n","Epoch 23\n","    Loss of the network on the 45000 training images: 232.1120818555355\n","    Accuracy of the network on the 45000 training images: 77.03999999999999%\n","    Accuracy of the network on the 5000 validation images: 77.48%\n","Epoch 24\n","    Loss of the network on the 45000 training images: 231.14468058943748\n","    Accuracy of the network on the 45000 training images: 77.15333333333334%\n","    Accuracy of the network on the 5000 validation images: 75.02%\n","Epoch 25\n","    Loss of the network on the 45000 training images: 231.45098969340324\n","    Accuracy of the network on the 45000 training images: 77.58666666666667%\n","    Accuracy of the network on the 5000 validation images: 74.06%\n","Epoch 26\n","    Loss of the network on the 45000 training images: 227.6029875576496\n","    Accuracy of the network on the 45000 training images: 77.64%\n","    Accuracy of the network on the 5000 validation images: 78.2%\n","Epoch 27\n","    Loss of the network on the 45000 training images: 227.09746339917183\n","    Accuracy of the network on the 45000 training images: 77.71111111111111%\n","    Accuracy of the network on the 5000 validation images: 73.36%\n","Epoch 28\n","    Loss of the network on the 45000 training images: 224.45247036218643\n","    Accuracy of the network on the 45000 training images: 78.01333333333334%\n","    Accuracy of the network on the 5000 validation images: 77.98%\n","Epoch 29\n","    Loss of the network on the 45000 training images: 224.23673623800278\n","    Accuracy of the network on the 45000 training images: 77.97333333333333%\n","    Accuracy of the network on the 5000 validation images: 75.3%\n","Epoch 30\n","    Loss of the network on the 45000 training images: 221.00037130713463\n","    Accuracy of the network on the 45000 training images: 78.63777777777777%\n","    Accuracy of the network on the 5000 validation images: 74.14%\n","Epoch 31\n","    Loss of the network on the 45000 training images: 221.50131541490555\n","    Accuracy of the network on the 45000 training images: 78.36888888888889%\n","    Accuracy of the network on the 5000 validation images: 70.58%\n","Epoch 32\n","    Loss of the network on the 45000 training images: 218.5045607984066\n","    Accuracy of the network on the 45000 training images: 78.47111111111111%\n","    Accuracy of the network on the 5000 validation images: 77.72%\n","Epoch 33\n","    Loss of the network on the 45000 training images: 219.40105605125427\n","    Accuracy of the network on the 45000 training images: 78.43555555555555%\n","    Accuracy of the network on the 5000 validation images: 73.1%\n","Epoch 34\n","    Loss of the network on the 45000 training images: 215.6120613515377\n","    Accuracy of the network on the 45000 training images: 78.97555555555556%\n","    Accuracy of the network on the 5000 validation images: 75.84%\n","Epoch 35\n","    Loss of the network on the 45000 training images: 218.21595567464828\n","    Accuracy of the network on the 45000 training images: 79.0%\n","    Accuracy of the network on the 5000 validation images: 71.34%\n","Epoch 36\n","    Loss of the network on the 45000 training images: 214.26057410240173\n","    Accuracy of the network on the 45000 training images: 79.12222222222223%\n","    Accuracy of the network on the 5000 validation images: 75.7%\n","Epoch 37\n","    Loss of the network on the 45000 training images: 216.53431925177574\n","    Accuracy of the network on the 45000 training images: 78.94444444444444%\n","    Accuracy of the network on the 5000 validation images: 71.72%\n","Epoch 38\n","    Loss of the network on the 45000 training images: 212.5412312746048\n","    Accuracy of the network on the 45000 training images: 79.32000000000001%\n","    Accuracy of the network on the 5000 validation images: 79.54%\n","Epoch 39\n","    Loss of the network on the 45000 training images: 212.3555472791195\n","    Accuracy of the network on the 45000 training images: 79.36222222222223%\n","    Accuracy of the network on the 5000 validation images: 77.60000000000001%\n","Epoch 40\n","    Loss of the network on the 45000 training images: 215.82897967100143\n","    Accuracy of the network on the 45000 training images: 79.14222222222223%\n","    Accuracy of the network on the 5000 validation images: 77.44%\n","Epoch 41\n","    Loss of the network on the 45000 training images: 212.41561311483383\n","    Accuracy of the network on the 45000 training images: 79.4511111111111%\n","    Accuracy of the network on the 5000 validation images: 64.60000000000001%\n","Epoch 42\n","    Loss of the network on the 45000 training images: 210.2831714451313\n","    Accuracy of the network on the 45000 training images: 79.52444444444444%\n","    Accuracy of the network on the 5000 validation images: 73.9%\n","Epoch 43\n","    Loss of the network on the 45000 training images: 209.75312101840973\n","    Accuracy of the network on the 45000 training images: 79.62666666666667%\n","    Accuracy of the network on the 5000 validation images: 73.0%\n","Epoch 44\n","    Loss of the network on the 45000 training images: 208.6550434231758\n","    Accuracy of the network on the 45000 training images: 79.82444444444444%\n","    Accuracy of the network on the 5000 validation images: 78.32000000000001%\n","Epoch 45\n","    Loss of the network on the 45000 training images: 208.52855002880096\n","    Accuracy of the network on the 45000 training images: 79.86222222222223%\n","    Accuracy of the network on the 5000 validation images: 75.03999999999999%\n","Epoch 46\n","    Loss of the network on the 45000 training images: 207.25596225261688\n","    Accuracy of the network on the 45000 training images: 79.99333333333334%\n","    Accuracy of the network on the 5000 validation images: 74.4%\n","Epoch 47\n","    Loss of the network on the 45000 training images: 209.80045586824417\n","    Accuracy of the network on the 45000 training images: 79.50888888888889%\n","    Accuracy of the network on the 5000 validation images: 74.96000000000001%\n","Epoch 48\n","    Loss of the network on the 45000 training images: 207.15500882267952\n","    Accuracy of the network on the 45000 training images: 80.0%\n","    Accuracy of the network on the 5000 validation images: 77.25999999999999%\n","Epoch 49\n","    Loss of the network on the 45000 training images: 205.19491159915924\n","    Accuracy of the network on the 45000 training images: 80.17777777777778%\n","    Accuracy of the network on the 5000 validation images: 79.5%\n","Epoch 50\n","    Loss of the network on the 45000 training images: 204.28672245144844\n","    Accuracy of the network on the 45000 training images: 80.37777777777778%\n","    Accuracy of the network on the 5000 validation images: 76.96%\n","Epoch 51\n","    Loss of the network on the 45000 training images: 153.47602908313274\n","    Accuracy of the network on the 45000 training images: 85.1888888888889%\n","    Accuracy of the network on the 5000 validation images: 84.78%\n","Epoch 52\n","    Loss of the network on the 45000 training images: 140.3589723110199\n","    Accuracy of the network on the 45000 training images: 86.60444444444444%\n","    Accuracy of the network on the 5000 validation images: 85.14%\n","Epoch 53\n","    Loss of the network on the 45000 training images: 134.05589185655117\n","    Accuracy of the network on the 45000 training images: 87.08444444444444%\n","    Accuracy of the network on the 5000 validation images: 85.28%\n","Epoch 54\n","    Loss of the network on the 45000 training images: 130.9597843438387\n","    Accuracy of the network on the 45000 training images: 87.27111111111111%\n","    Accuracy of the network on the 5000 validation images: 85.8%\n","Epoch 55\n","    Loss of the network on the 45000 training images: 125.74486392736435\n","    Accuracy of the network on the 45000 training images: 87.94444444444444%\n","    Accuracy of the network on the 5000 validation images: 85.98%\n","Epoch 56\n","    Loss of the network on the 45000 training images: 122.3638195246458\n","    Accuracy of the network on the 45000 training images: 88.06888888888889%\n","    Accuracy of the network on the 5000 validation images: 86.06%\n","Epoch 57\n","    Loss of the network on the 45000 training images: 120.86960932612419\n","    Accuracy of the network on the 45000 training images: 88.27333333333334%\n","    Accuracy of the network on the 5000 validation images: 86.02%\n","Epoch 58\n","    Loss of the network on the 45000 training images: 117.45117825269699\n","    Accuracy of the network on the 45000 training images: 88.55555555555556%\n","    Accuracy of the network on the 5000 validation images: 86.42%\n","Epoch 59\n","    Loss of the network on the 45000 training images: 116.59310393035412\n","    Accuracy of the network on the 45000 training images: 88.67333333333333%\n","    Accuracy of the network on the 5000 validation images: 85.7%\n","Epoch 60\n","    Loss of the network on the 45000 training images: 112.68133878707886\n","    Accuracy of the network on the 45000 training images: 89.19111111111111%\n","    Accuracy of the network on the 5000 validation images: 86.33999999999999%\n","Epoch 61\n","    Loss of the network on the 45000 training images: 113.09421491622925\n","    Accuracy of the network on the 45000 training images: 89.09333333333333%\n","    Accuracy of the network on the 5000 validation images: 86.66%\n","Epoch 62\n","    Loss of the network on the 45000 training images: 109.71437533199787\n","    Accuracy of the network on the 45000 training images: 89.41111111111111%\n","    Accuracy of the network on the 5000 validation images: 86.22%\n","Epoch 63\n","    Loss of the network on the 45000 training images: 110.13375514745712\n","    Accuracy of the network on the 45000 training images: 89.44666666666666%\n","    Accuracy of the network on the 5000 validation images: 86.7%\n","Epoch 64\n","    Loss of the network on the 45000 training images: 106.62013268470764\n","    Accuracy of the network on the 45000 training images: 89.54444444444445%\n","    Accuracy of the network on the 5000 validation images: 86.68%\n","Epoch 65\n","    Loss of the network on the 45000 training images: 107.44895127415657\n","    Accuracy of the network on the 45000 training images: 89.57777777777778%\n","    Accuracy of the network on the 5000 validation images: 86.08%\n","Epoch 66\n","    Loss of the network on the 45000 training images: 105.4764466136694\n","    Accuracy of the network on the 45000 training images: 89.91777777777777%\n","    Accuracy of the network on the 5000 validation images: 86.9%\n","Epoch 67\n","    Loss of the network on the 45000 training images: 104.36523973941803\n","    Accuracy of the network on the 45000 training images: 89.84444444444445%\n","    Accuracy of the network on the 5000 validation images: 86.56%\n","Epoch 68\n","    Loss of the network on the 45000 training images: 102.50366422533989\n","    Accuracy of the network on the 45000 training images: 90.22444444444444%\n","    Accuracy of the network on the 5000 validation images: 87.06%\n","Epoch 69\n","    Loss of the network on the 45000 training images: 101.31243006885052\n","    Accuracy of the network on the 45000 training images: 90.2088888888889%\n","    Accuracy of the network on the 5000 validation images: 87.18%\n","Epoch 70\n","    Loss of the network on the 45000 training images: 102.08787074685097\n","    Accuracy of the network on the 45000 training images: 90.06222222222222%\n","    Accuracy of the network on the 5000 validation images: 86.72%\n","Epoch 71\n","    Loss of the network on the 45000 training images: 99.22692868113518\n","    Accuracy of the network on the 45000 training images: 90.42444444444445%\n","    Accuracy of the network on the 5000 validation images: 87.02%\n","Epoch 72\n","    Loss of the network on the 45000 training images: 98.82508351653814\n","    Accuracy of the network on the 45000 training images: 90.52444444444444%\n","    Accuracy of the network on the 5000 validation images: 86.98%\n","Epoch 73\n","    Loss of the network on the 45000 training images: 96.12067972123623\n","    Accuracy of the network on the 45000 training images: 90.72222222222223%\n","    Accuracy of the network on the 5000 validation images: 86.83999999999999%\n","Epoch 74\n","    Loss of the network on the 45000 training images: 96.56271766126156\n","    Accuracy of the network on the 45000 training images: 90.67777777777778%\n","    Accuracy of the network on the 5000 validation images: 86.7%\n","Epoch 75\n","    Loss of the network on the 45000 training images: 95.2848427966237\n","    Accuracy of the network on the 45000 training images: 90.72%\n","    Accuracy of the network on the 5000 validation images: 86.4%\n","Epoch 76\n","    Loss of the network on the 45000 training images: 87.98490627110004\n","    Accuracy of the network on the 45000 training images: 91.63333333333334%\n","    Accuracy of the network on the 5000 validation images: 87.2%\n","Epoch 77\n","    Loss of the network on the 45000 training images: 85.92919139564037\n","    Accuracy of the network on the 45000 training images: 91.68222222222222%\n","    Accuracy of the network on the 5000 validation images: 87.44%\n","Epoch 78\n","    Loss of the network on the 45000 training images: 84.90873024612665\n","    Accuracy of the network on the 45000 training images: 91.85555555555555%\n","    Accuracy of the network on the 5000 validation images: 87.56%\n","Epoch 79\n","    Loss of the network on the 45000 training images: 84.22257582098246\n","    Accuracy of the network on the 45000 training images: 91.89333333333335%\n","    Accuracy of the network on the 5000 validation images: 87.42%\n","Epoch 80\n","    Loss of the network on the 45000 training images: 84.57958402484655\n","    Accuracy of the network on the 45000 training images: 91.85555555555555%\n","    Accuracy of the network on the 5000 validation images: 87.5%\n","Epoch 81\n","    Loss of the network on the 45000 training images: 85.20837205648422\n","    Accuracy of the network on the 45000 training images: 91.83555555555556%\n","    Accuracy of the network on the 5000 validation images: 87.5%\n","Epoch 82\n","    Loss of the network on the 45000 training images: 83.13409803062677\n","    Accuracy of the network on the 45000 training images: 92.00888888888889%\n","    Accuracy of the network on the 5000 validation images: 87.53999999999999%\n","Epoch 83\n","    Loss of the network on the 45000 training images: 83.95681428164244\n","    Accuracy of the network on the 45000 training images: 91.92222222222223%\n","    Accuracy of the network on the 5000 validation images: 87.3%\n","Epoch 84\n","    Loss of the network on the 45000 training images: 82.22610554844141\n","    Accuracy of the network on the 45000 training images: 92.08666666666666%\n","    Accuracy of the network on the 5000 validation images: 87.6%\n","Epoch 85\n","    Loss of the network on the 45000 training images: 82.427111312747\n","    Accuracy of the network on the 45000 training images: 92.0311111111111%\n","    Accuracy of the network on the 5000 validation images: 87.58%\n","Epoch 86\n","    Loss of the network on the 45000 training images: 82.00145509839058\n","    Accuracy of the network on the 45000 training images: 92.18666666666667%\n","    Accuracy of the network on the 5000 validation images: 87.42%\n","Epoch 87\n","    Loss of the network on the 45000 training images: 82.56583289057016\n","    Accuracy of the network on the 45000 training images: 92.16888888888889%\n","    Accuracy of the network on the 5000 validation images: 87.6%\n","Epoch 88\n","    Loss of the network on the 45000 training images: 81.37039022892714\n","    Accuracy of the network on the 45000 training images: 92.13333333333334%\n","    Accuracy of the network on the 5000 validation images: 87.4%\n","Epoch 89\n","    Loss of the network on the 45000 training images: 80.52540718764067\n","    Accuracy of the network on the 45000 training images: 92.37333333333333%\n","    Accuracy of the network on the 5000 validation images: 87.33999999999999%\n","Epoch 90\n","    Loss of the network on the 45000 training images: 81.55793159455061\n","    Accuracy of the network on the 45000 training images: 92.12666666666667%\n","    Accuracy of the network on the 5000 validation images: 87.33999999999999%\n","Epoch 91\n","    Loss of the network on the 45000 training images: 79.75802472233772\n","    Accuracy of the network on the 45000 training images: 92.28888888888889%\n","    Accuracy of the network on the 5000 validation images: 87.62%\n","Epoch 92\n","    Loss of the network on the 45000 training images: 80.00334505736828\n","    Accuracy of the network on the 45000 training images: 92.28222222222222%\n","    Accuracy of the network on the 5000 validation images: 87.86%\n","Epoch 93\n","    Loss of the network on the 45000 training images: 79.56561832129955\n","    Accuracy of the network on the 45000 training images: 92.30222222222221%\n","    Accuracy of the network on the 5000 validation images: 87.3%\n","Epoch 94\n","    Loss of the network on the 45000 training images: 79.43530765920877\n","    Accuracy of the network on the 45000 training images: 92.24888888888889%\n","    Accuracy of the network on the 5000 validation images: 87.64%\n","Epoch 95\n","    Loss of the network on the 45000 training images: 80.90678206831217\n","    Accuracy of the network on the 45000 training images: 92.27111111111111%\n","    Accuracy of the network on the 5000 validation images: 87.64%\n","Epoch 96\n","    Loss of the network on the 45000 training images: 78.69999285787344\n","    Accuracy of the network on the 45000 training images: 92.43333333333334%\n","    Accuracy of the network on the 5000 validation images: 87.6%\n","Epoch 97\n","    Loss of the network on the 45000 training images: 80.78503858298063\n","    Accuracy of the network on the 45000 training images: 92.28222222222222%\n","    Accuracy of the network on the 5000 validation images: 87.74%\n","Epoch 98\n","    Loss of the network on the 45000 training images: 80.20864136517048\n","    Accuracy of the network on the 45000 training images: 92.27111111111111%\n","    Accuracy of the network on the 5000 validation images: 87.58%\n","Epoch 99\n","    Loss of the network on the 45000 training images: 78.55125898867846\n","    Accuracy of the network on the 45000 training images: 92.5288888888889%\n","    Accuracy of the network on the 5000 validation images: 87.66000000000001%\n","Epoch 100\n","    Loss of the network on the 45000 training images: 77.84818850457668\n","    Accuracy of the network on the 45000 training images: 92.41555555555556%\n","    Accuracy of the network on the 5000 validation images: 87.3%\n","Finished Training\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9y1FESd5IDyh","executionInfo":{"status":"ok","timestamp":1626838632371,"user_tz":-330,"elapsed":20,"user":{"displayName":"Abhirath Anand","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgK3G6ETxbNbUGxfG49-G1F7hu8ECK1VefIB-8NKA=s64","userId":"10495731995593710191"}}},"source":["# saving model\n","model_save_name = 'cifarvgglike.pt'\n","path = f\"/content/gdrive/My Drive/Deep Learning/pytorch-experiments/Vision/models/{model_save_name}\" \n","torch.save(net, path)"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"RjNE2vpSJAm5","executionInfo":{"status":"ok","timestamp":1626838632999,"user_tz":-330,"elapsed":631,"user":{"displayName":"Abhirath Anand","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgK3G6ETxbNbUGxfG49-G1F7hu8ECK1VefIB-8NKA=s64","userId":"10495731995593710191"}}},"source":["# loading model\n","model_save_name = 'cifarvgglike.pt'\n","PATH = f\"/content/gdrive/My Drive/Deep Learning/pytorch-experiments/Vision/models/{model_save_name}\"\n","model = torch.load(PATH, map_location=torch.device(device))"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"s7YuwXdpXRqE","executionInfo":{"status":"ok","timestamp":1626838632999,"user_tz":-330,"elapsed":3,"user":{"displayName":"Abhirath Anand","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgK3G6ETxbNbUGxfG49-G1F7hu8ECK1VefIB-8NKA=s64","userId":"10495731995593710191"}}},"source":["# moving model to GPU\n","model.to(device);"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"Wts_BReX4nZ4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626838635213,"user_tz":-330,"elapsed":2216,"user":{"displayName":"Abhirath Anand","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgK3G6ETxbNbUGxfG49-G1F7hu8ECK1VefIB-8NKA=s64","userId":"10495731995593710191"}},"outputId":"46a6aeca-831b-40b7-f2e1-d0ad1ebc4001"},"source":["# evaluating on test set\n","correct = 0\n","total = 0\n","# since we're not training, we don't need to calculate the gradients for our outputs\n","with torch.no_grad():\n","    model.eval()\n","    for data in testloader:\n","        images, labels = data\n","        images, labels = images.to(device), labels.to(device)\n","        # calculate outputs by running images through the network\n","        outputs = model(images)\n","        # the class with the highest energy is what we choose as prediction\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","print(f'Accuracy of the network on the {total} test images: {100 * correct / total}')"],"execution_count":22,"outputs":[{"output_type":"stream","text":["Accuracy of the network on the 10000 test images: 87.19\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SYoThMPU5HvK","executionInfo":{"status":"ok","timestamp":1626838635213,"user_tz":-330,"elapsed":8,"user":{"displayName":"Abhirath Anand","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgK3G6ETxbNbUGxfG49-G1F7hu8ECK1VefIB-8NKA=s64","userId":"10495731995593710191"}}},"source":[""],"execution_count":22,"outputs":[]}]}